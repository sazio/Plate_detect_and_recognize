{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "[Part 1]License_plate_detection.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "svVzGQwg7fq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e2cd585-4cdc-4aae-e9c3-a8fdefff0f98"
      },
      "source": [
        "!git clone https://github.com/sazio/Plate_detect_and_recognize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Plate_detect_and_recognize' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO5CCVji6__N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"Plate_detect_and_recognize\")\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from local_utils import detect_lp\n",
        "from os.path import splitext,basename\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import glob\n",
        "\n",
        "import matplotlib.gridspec as gridspec"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkTFg4O6__S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(path):\n",
        "    try:\n",
        "        path = splitext(path)[0]\n",
        "        with open('%s.json' % path, 'r') as json_file:\n",
        "            model_json = json_file.read()\n",
        "        model = model_from_json(model_json, custom_objects={})\n",
        "        model.load_weights('%s.h5' % path)\n",
        "        print(\"Loading model successfully...\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFl7X62D6__W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35f11597-9677-4698-91e2-9ba17e53fe1e"
      },
      "source": [
        "# Load WPOD NET - Plate Detection\n",
        "wpod_net_path = \"wpod-net.json\"\n",
        "wpod_net = load_model(wpod_net_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model successfully...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt1ygx6wETcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "660d7629-61ac-45b5-bc72-d316d39e5a47"
      },
      "source": [
        "# Load MOBILE NET - letters detection \n",
        "json_file_mob_net = open('MobileNets_character_recognition.json', 'r')\n",
        "loaded_model_json_mob_net = json_file_mob_net.read()\n",
        "json_file_mob_net.close()\n",
        "model_mob_net = model_from_json(loaded_model_json_mob_net)\n",
        "model_mob_net.load_weights(\"License_character_recognition_weight.h5\")\n",
        "print(\"[INFO] Model loaded successfully...\")\n",
        "\n",
        "labels_plate = LabelEncoder()\n",
        "labels_plate.classes_ = np.load('license_character_classes.npy')\n",
        "print(\"[INFO] Labels loaded successfully...\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Model loaded successfully...\n",
            "[INFO] Labels loaded successfully...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz8uXt-G6__Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(image_path,resize=False):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img / 255\n",
        "    if resize:\n",
        "        img = cv2.resize(img, (224,224))\n",
        "    return img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJYUiKhYEiQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-processing input images and predict with model (Mobile Net)\n",
        "def predict_from_model(image,model,labels):\n",
        "    image = cv2.resize(image,(80,80))\n",
        "    image = np.stack((image,)*3, axis=-1)\n",
        "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n",
        "    return prediction"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "67ZqtUMN6__c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0426c673-06c7-42ee-b5c3-966105ece46e"
      },
      "source": [
        "# Create a list of image paths \n",
        "image_paths = glob.glob(\"Plate_examples/*.jpg\")\n",
        "print(\"Found %i images...\"%(len(image_paths)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18 images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4TUQSsgG6__f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# forward image through model and return plate's image and coordinates\n",
        "# if error \"No Licensese plate is founded!\" pop up, try to adjust Dmin\n",
        "def get_plate(image_path, Dmax=608, Dmin=256):\n",
        "    vehicle = preprocess_image(image_path)\n",
        "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
        "    side = int(ratio * Dmin)\n",
        "    bound_dim = min(side, Dmax)\n",
        "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
        "    return vehicle, LpImg, cor"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fzVWML66__i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_box(image_path, cor, thickness=3): \n",
        "    pts=[]  \n",
        "    x_coordinates=cor[0][0]\n",
        "    y_coordinates=cor[0][1]\n",
        "    # store the top-left, top-right, bottom-left, bottom-right \n",
        "    # of the plate license respectively\n",
        "    for i in range(4):\n",
        "        pts.append([int(x_coordinates[i]),int(y_coordinates[i])])\n",
        "    \n",
        "    pts = np.array(pts, np.int32)\n",
        "    pts = pts.reshape((-1,1,2))\n",
        "    vehicle_image = preprocess_image(image_path)\n",
        "    \n",
        "    cv2.polylines(vehicle_image,[pts],True,(0,255,0),thickness)\n",
        "    return vehicle_image\n",
        "\n",
        "\"\"\"plt.figure(figsize=(8,8))\n",
        "plt.axis(False)\n",
        "plt.imshow(draw_box(test_image,cor))\"\"\";"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lLvaKTA9yW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%timeit --> 304 ms \n",
        "#################\n",
        "test_image_path = \"Plate_examples/germany_car_plate.jpg\"\n",
        "vehicle, LpImg, cor = get_plate(test_image_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAfEcULt-Nt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%timeit --> 497 µs\n",
        "if (len(LpImg)): #check if there is at least one license image\n",
        "    # Scales, calculates absolute values, and converts the result to 8-bit.\n",
        "    plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n",
        "    \n",
        "    # convert to grayscale and blur the image\n",
        "    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray,(7,7),0)\n",
        "    \n",
        "    # Applied inversed thresh_binary \n",
        "    binary = cv2.threshold(blur, 180, 255,\n",
        "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "    \n",
        "    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uglw2Wrq9yV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%timeit 360 µs\n",
        "# Create sort_contours() function to grab the contour of each digit from left to right\n",
        "def sort_contours(cnts,reverse = False):\n",
        "    i = 0\n",
        "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "                                        key=lambda b: b[1][i], reverse=reverse))\n",
        "    return cnts\n",
        "\n",
        "cont, _  = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# creat a copy version \"test_roi\" of plat_image to draw bounding box\n",
        "test_roi = plate_image.copy()\n",
        "\n",
        "# Initialize a list which will be used to append charater image\n",
        "crop_characters = []\n",
        "\n",
        "# define standard width and height of character\n",
        "digit_w, digit_h = 30, 60\n",
        "\n",
        "for c in sort_contours(cont):\n",
        "    (x, y, w, h) = cv2.boundingRect(c)\n",
        "    ratio = h/w\n",
        "    if 1<=ratio<=3.5: # Only select contour with defined ratio\n",
        "        if h/plate_image.shape[0]>=0.5: # Select contour which has the height larger than 50% of the plate\n",
        "            # Draw bounding box arroung digit number\n",
        "            cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255,0), 2)\n",
        "\n",
        "            # Sperate number and gibe prediction\n",
        "            curr_num = thre_mor[y:y+h,x:x+w]\n",
        "            curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
        "            _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            crop_characters.append(curr_num)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmQTkuKsA99j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97954263-586b-4d46-ceb1-99ffd0aa4f3e"
      },
      "source": [
        "#%%timeit 329 ms\n",
        "#fig = plt.figure(figsize=(15,3))\n",
        "#cols = len(crop_characters)\n",
        "#grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\n",
        "\n",
        "final_string = ''\n",
        "for i,character in enumerate(crop_characters):\n",
        "    #fig.add_subplot(grid[i])\n",
        "    title = np.array2string(predict_from_model(character,model_mob_net,labels_plate))\n",
        "    #plt.title('{}'.format(title.strip(\"'[]\"),fontsize=20))\n",
        "    final_string+=title.strip(\"'[]\")\n",
        "    #plt.axis(False)\n",
        "    #plt.imshow(character,cmap='gray')\n",
        "\n",
        "print(final_string)\n",
        "#plt.savefig('final_result.png', dpi=300)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KPC1313\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}